{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igMyGnjE9hEp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2HDvhIu9hEr"
   },
   "source": [
    "# Specify each path\n",
    "\n",
    "数据从csv文件中获取，先转成标准模型，再转成tflite，如下变量为对应的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NvZP2Zn9hEy"
   },
   "outputs": [],
   "source": [
    "dataset = 'hands.csv'\n",
    "model_save_path = 'HandTurnPage.hdf5'\n",
    "tflite_save_path = 'HandTurnPage.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5oMH7x19hEz"
   },
   "source": [
    "# Set number of classes\n",
    "\n",
    "最终数据分为4类，也就是数据为4个分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "du4kodXL9hEz"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnL0uso9hEz"
   },
   "source": [
    "# Dataset reading\n",
    "\n",
    "从csv中获取数据\n",
    "\n",
    "* 第1列以及之后的是输入数据X_dataset\n",
    "* 第0列为模型输出数据y_dataset\n",
    "* train_test_split()采用RANDOM_SEED来随机分配训练数据和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QT5ZqtEz9hE0"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 3) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmoKFsp49hE0"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQU7JTZ_9hE0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxK_lETT9hE0"
   },
   "source": [
    "# Model building\n",
    "\n",
    "建立模型\n",
    "\n",
    "* 最常见的模型是层的堆叠：tf.keras.models.Sequential。即层的线性叠加\n",
    "* Dropout: 随机丢弃输入数据，防止过拟合，提高模型的泛化能力\n",
    "  * [第16章 使用Dropout正则化防止过拟合](https://cnbeining.github.io/deep-learning-with-python-cn/4-advanced-multi-layer-perceptrons-and-keras/ch16-reduce-overfitting-with-dropout-regularization.html)\n",
    "    * Dropout的意思是：每次训练时随机忽略一部分神经元，这些神经元dropped-out了。换句话讲，这些神经元在正向传播时对下游的启动影响被忽略，反向传播时也不会更新权重。\n",
    "* Dense: 全连接层\n",
    "  * units: 正整数，输出空间维度\n",
    "  * activation: 使用什么激活函数（神经网络的非线性层），默认为None，不使用激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHBmUf1t9hE1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 3, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypqky9tc9hE1"
   },
   "outputs": [],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbMjOflQ9hE1"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3Dac0M_9hE2"
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XI0j1Iu9hE2"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WirBl-JE9hE3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxvb2Y299hE3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失、精度曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validataion Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validataion Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# 设置绘图尺寸\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBkmDeUW9hE4"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFz9Tb0I9hE4"
   },
   "outputs": [],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(X_test[0])\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNP6aqzc9hE5"
   },
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODjnYyld9hE6"
   },
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRfuK8Y59hE6"
   },
   "outputs": [],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJksKTpolHJn"
   },
   "source": [
    "# TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G-aB5VNk4HV"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fk2uVfP9k79d"
   },
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y54jp8s_k87N"
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvmI5ha3lBOJ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxQydpNAlEDe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0023_HandGesture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
