# rpi4 MediaPipe

树莓派系统安装MediaPipe，FPS只能达到6帧

# 参考文档

* [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands#python-solution-api)

# system version

* rpi system download
  * https://downloads.raspberrypi.org/
  * https://downloads.raspberrypi.org/raspios_full_armhf/images/
* cat /proc/version
  ```
  Linux version 5.4.83-v7l (pi@raspberrypi) (gcc version 8.3.0 (Raspbian 8.3.0-6+rpi1)) #1 SMP Sun Mar 21 02:17:27 GMT 2021
  ```
* https://downloads.raspberrypi.org/raspios_full_armhf/images/raspios_full_armhf-2021-03-25/
* python3 --version
  ```
  Python 3.7.3
  ```
  * [0009_BuildPythonSource.md](0009_BuildPythonSource.md)

# OpenCV Install

* `sudo cat /etc/apt/sources.list`
  ```
  deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contrib rpi
  deb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ buster main non-free contrib rpi
  
  deb http://mirrors.tuna.tsinghua.edu.cn/raspberrypi/ buster main ui
  ```
* sudo apt-get update
* sudo apt-get install libgtk2.0-dev
  * opencv image show会用到gtk
* 获取支持的opencv-python版本，version.py脚本内容如下
  ```python
  #!/usr/bin/env python3

  import json
  import sys
  from urllib import request
  from pkg_resources import parse_version

  def versions(pkg_name):
      url = f'https://pypi.python.org/pypi/{pkg_name}/json'
      releases = json.loads(request.urlopen(url).read())['releases']
      # return sorted(releases, key=parse_version, reverse=True)
      return sorted(releases, key=parse_version)

  if __name__ == '__main__':
      print(*versions(sys.argv[1]), sep='\n')
  ```
  * python3 version.py opencv-python
    ```
    3.1.0
    3.1.0.0
    3.1.0.1
    3.1.0.2
    3.1.0.3
    3.1.0.4
    3.1.0.5
    3.2.0.6
    3.2.0.7
    3.2.0.8
    3.3.0.10
    3.3.0.9
    3.3.1.11
    3.4.0.12
    3.4.0.14
    3.4.1.15
    3.4.10.35
    3.4.10.37
    3.4.11.39
    3.4.11.41
    3.4.11.43
    3.4.11.45
    3.4.13.47
    3.4.14.51
    ...
    ```
* sudo pip3 install opencv-python==3.1.0
  ```
  Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.tuna.tsinghua.edu.cn/simple
  Collecting opencv-python==3.1.0
    Could not find a version that satisfies the requirement opencv-python==3.1.0 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62)
  No matching distribution found for opencv-python==3.1.0
  ```
  * 3.4.0.14
    * sudo apt-get install qt4-default
      * 3.4.0.14依赖qt4
    * export MAKEFLAGS="-j$(nproc)"
    * sudo pip3 install opencv-python==3.4.0.14
      * [树莓派安装opencv报错：make[2]: *** [modules/python3/CMakeFiles/opencv_python3.dir/build.make:56...](https://blog.csdn.net/qq_44357371/article/details/105966714)
  * sudo pip3 install opencv-python==4.3.0.38
    * 安装成功

# 安装 TensorFlow Lite 解释器

* https://www.tensorflow.org/lite/guide/python?hl=zh-cn#%E5%AE%89%E8%A3%85_tensorflow_lite_%E8%A7%A3%E9%87%8A%E5%99%A8
  * pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl
    * cp37
      * python 3.7
    * tflite_runtime-2.1.0
      * tensorflow lite 2.1.0
* [0008_TF_fix_Version_tflite.md](0008_TF_fix_Version_tflite.md)

# MediaPipe Hands

* sudo pip3 install mediapipe-rpi4
* [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands#python-solution-api)
* 在树莓派上运行，fps：6，性能上比不上直接在Android运行

```python
import cv2
import mediapipe as mp
import time

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands

# For static images:
IMAGE_FILES = []
with mp_hands.Hands(
    static_image_mode=True,
    max_num_hands=2,
    min_detection_confidence=0.5) as hands:
  for idx, file in enumerate(IMAGE_FILES):
    # Read an image, flip it around y-axis for correct handedness output (see
    # above).
    image = cv2.flip(cv2.imread(file), 1)
    # Convert the BGR image to RGB before processing.
    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Print handedness and draw hand landmarks on the image.
    print('Handedness:', results.multi_handedness)
    if not results.multi_hand_landmarks:
      continue
    image_height, image_width, _ = image.shape
    annotated_image = image.copy()
    for hand_landmarks in results.multi_hand_landmarks:
      print('hand_landmarks:', hand_landmarks)
      print(
          f'Index finger tip coordinates: (',
          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '
          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'
      )
      mp_drawing.draw_landmarks(
          annotated_image,
          hand_landmarks,
          mp_hands.HAND_CONNECTIONS,
          mp_drawing_styles.get_default_hand_landmarks_style(),
          mp_drawing_styles.get_default_hand_connections_style())
    cv2.imwrite(
        '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))
    # Draw hand world landmarks.
    if not results.multi_hand_world_landmarks:
      continue
    for hand_world_landmarks in results.multi_hand_world_landmarks:
      mp_drawing.plot_landmarks(
        hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)

# used to record the time when we processed last frame
prev_frame_time = 0
# used to record the time at which we processed current frame
new_frame_time = 0

# For webcam input:
cap = cv2.VideoCapture(0)
with mp_hands.Hands(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as hands:
  while cap.isOpened():
    success, image = cap.read()
    if not success:
      print("Ignoring empty camera frame.")
      # If loading a video, use 'break' instead of 'continue'.
      continue

    # To improve performance, optionally mark the image as not writeable to
    # pass by reference.
    image.flags.writeable = False
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = hands.process(image)

    # Draw the hand annotations on the image.
    image.flags.writeable = True
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    if results.multi_hand_landmarks:
      for hand_landmarks in results.multi_hand_landmarks:
        mp_drawing.draw_landmarks(
            image,
            hand_landmarks,
            mp_hands.HAND_CONNECTIONS,
            mp_drawing_styles.get_default_hand_landmarks_style(),
            mp_drawing_styles.get_default_hand_connections_style())

    # font which we will be using to display FPS
    font = cv2.FONT_HERSHEY_SIMPLEX
    # time when we finish processing for this frame
    new_frame_time = time.time()

    # Calculating the fps

    # fps will be number of frame processed in given time frame
    # since their will be most of time error of 0.001 second
    # we will be subtracting it to get more accurate result
    fps = 1/(new_frame_time-prev_frame_time)
    print(str(new_frame_time-prev_frame_time) + " ms")
    prev_frame_time = new_frame_time

    cv2.putText(image, str(int(fps)), (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)

    # Flip the image horizontally for a selfie-view display.
    cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))
    if cv2.waitKey(5) & 0xFF == 27:
      break
cap.release()
```
